{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class perceptron(object):\n",
    "  \n",
    "    def __init__ (self, n_layers=1, n_inputs=1):\n",
    "        self.n_layers = n_layers\n",
    "        self.n_inputs = n_inputs\n",
    "        \n",
    "        print 'Shell_init: layers ',n_layers,' inputs ', n_inputs\n",
    "        \n",
    "        self.layers = []\n",
    "        for i in range(self.n_layers):\n",
    "            self.layers.append(self.layer(i+1))\n",
    "        \n",
    "        self.build()\n",
    "            \n",
    "            \n",
    "            \n",
    "    def build (self):\n",
    "        'Initialize weight matrix throught all layers'\n",
    "        print 'Shell_build'\n",
    "        inp = self.n_inputs\n",
    "        for i in self.layers:\n",
    "            i.build(inp)\n",
    "            inp = i.size\n",
    "               \n",
    "            \n",
    "            \n",
    "    def add_neuron(self, tier, ftype=('t',0.5)):\n",
    "        'Add neuron to specific tier'\n",
    "        print 'Shell_add_neuron'\n",
    "        self.layers[tier-1].add_neuron(ftype)\n",
    "        self.build()\n",
    "\n",
    "        \n",
    "        \n",
    "    def set_neuron(self, pos, ftype):\n",
    "        if type(pos) is int: pos = [pos]\n",
    "        assert len(pos) < 3\n",
    "        if len(pos) == 1:\n",
    "            for i in self.layers[pos[0]-1].neurons:\n",
    "                i.ftype = ftype\n",
    "            print 'Changing neurons in: tier', pos[0], 'to function:', ftype\n",
    "        else:\n",
    "            self.layers[pos[0]-1].neurons[pos[1]-1].ftype = ftype\n",
    "            print 'Changing neuron: tier', pos[0], '#' + str(pos[1]), 'to function:', ftype\n",
    "    \n",
    "    \n",
    "    def show_weights(self):\n",
    "        for i in self.layers:\n",
    "            i.show_weights()\n",
    "        \n",
    "            \n",
    "            \n",
    "    def push(self, x):\n",
    "        'Input value and propagate it thruogh the network'\n",
    "        x = np.asarray(x)\n",
    "        x = x.reshape(1,-1)\n",
    "        assert x.shape[1] == self.n_inputs\n",
    "        print '\\nShell_push \\ninput vector:\\n', x\n",
    "        for i in self.layers:\n",
    "            x = i.push(x)\n",
    "        \n",
    "#         return x\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    class layer(object):\n",
    "        \n",
    "        def __init__ (self, tier):\n",
    "            \n",
    "            self.size = 1\n",
    "            self.tier = tier\n",
    "            print ' Layer_init: tier',self.tier,'size ', self.size\n",
    "            \n",
    "            self.neurons = []\n",
    "            for i in range(self.size):\n",
    "                self.neurons.append(self.neuron(('t', 0.5),i+1))\n",
    "            \n",
    "            \n",
    "        def build(self, inputs):\n",
    "            print ' Layer_build: ', 'tier', self.tier\n",
    "            self.w = np.random.random_sample((inputs, self.size))\n",
    "            \n",
    "        def show_weights(self):    \n",
    "            print 'Layer ', self.number, ' w-matrix:\\n', self.w\n",
    "            \n",
    "        def add_neuron(self, ftype):\n",
    "            print ' Layer_add_neuron'\n",
    "            self.size += 1\n",
    "            self.neurons.append(self.neuron(ftype, self.size))\n",
    "            \n",
    "            \n",
    "        def push(self, x):\n",
    "            print ' Layer_push\\n wmatrix:\\n', self.w\n",
    "            x = x.dot(self.w)\n",
    "            for i in enumerate(self.neurons):\n",
    "                x[0,i[0]] = i[1].push(x[0,i[0]])\n",
    "#             return x\n",
    "                \n",
    "                \n",
    "        \n",
    "        \n",
    "        class neuron(object):\n",
    "            \n",
    "#             @staticmethod\n",
    "#             def threshold(x, a):\n",
    "#                 print '   neuron_func_threshold'\n",
    "#                 return 1 if x >= a else 0\n",
    "            \n",
    "#             @staticmethod\n",
    "#             def sigmoid(x, a):\n",
    "#                 print 'neuron_func_sigmoid'\n",
    "#                 return 1/(1+np.exp(-x))\n",
    "             \n",
    "            @staticmethod\n",
    "            def func(ftype, x):\n",
    "                if ftype[0] == 't':\n",
    "                    return 1 if x >= ftype[1] else 0\n",
    "                elif ftype =='s':\n",
    "                    return 1/(1+np.exp(-x))\n",
    "\n",
    "            \n",
    "            \n",
    "            def __init__(self, ftype, num):\n",
    "                print '  Neuron_init: type', ftype\n",
    "                self.ftype = ftype\n",
    "                self.idx = num\n",
    "                \n",
    "                \n",
    "            def push(self, x):\n",
    "                out = perceptron.layer.neuron.func(self.ftype, x)\n",
    "                print '  Neuron_push: #',self.idx,'\\n  type:',self.ftype,'\\n', x, '->', out\n",
    "                return out\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shell_init: layers  1  inputs  2\n",
      " Layer_init: tier 1 size  1\n",
      "  Neuron_init: type ('t', 0.5)\n",
      "Shell_build\n",
      " Layer_build:  tier 1\n",
      "\n",
      "Shell_push \n",
      "input vector:\n",
      "[[1 0]]\n",
      " Layer_push\n",
      " wmatrix:\n",
      "[[ 0.08787234]\n",
      " [ 0.408597  ]]\n",
      "  Neuron_push: # 1 \n",
      "  type: ('t', 0.5) \n",
      "0.0878723407354 -> 0\n"
     ]
    }
   ],
   "source": [
    "a = perceptron(n_layers=1, n_inputs=2)\n",
    "# a.add_neuron(1,('t', 0.5))\n",
    "# a.add_neuron(2,'t')\n",
    "# a.set_neuron((1),('t', 0.5))\n",
    "a.push((1,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34777313816371047"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.layers[0].w.dot((1,0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = a.layers[0].w\n",
    "np.asarray(1).reshape(1,-1)[0,0]\n",
    "# .dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class cls(object):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    @staticmethod\n",
    "    def static():\n",
    "        print 'static world'\n",
    "        \n",
    "    def inst (self):\n",
    "        print self.data\n",
    "        cls.static()\n",
    "        \n",
    "a = cls(25)        \n",
    "a.inst()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
